---
title: "Analysis"
output: html_notebook
---
```{r}
# setting working directory and loading

setwd("C:/Users/Bruger/Desktop/BA/DataProcessing")
pacman::p_load(readr,brms,tidyverse,ggplot2, dplyr)

```


# Part 1 
checking if the previous models used in Tyl√©n et al. 2018 is the best option for the first hypothesis

```{r}
#Loading the data 
Strategy <- read_csv("Strategy_one_pr_pair.csv")
Strategy$Strategy <- as.ordered(Strategy$Strategy)
Strategy$Condition <- as.character(Strategy$Condition, levels = c('Individual','Constant Pair','Flex Pair'))

# changing the names to ensure the correct order in the plots
Strategy$Condition <- str_replace(Strategy$Condition, pattern = "Individual", "A_Individual")
Strategy$Condition <- str_replace(Strategy$Condition, pattern = "Constant Pair", "B_Constant Pair")
Strategy$Condition <- str_replace(Strategy$Condition, pattern = "Flex Pair", "C_Flex Pair")


# creating the different models
AbstractionModel0 <- brm(Strategy ~ 1, data=Strategy, family=cumulative("logit"))
AbstractionModel0 <- add_ic(AbstractionModel0,ic="loo")
AbstractionModel0 <- add_ic(AbstractionModel0,ic="kfold")

AbstractionModel1 <- brm(Strategy ~ 1 + Condition, data=Strategy, family=cumulative("logit"))
AbstractionModel1 <- add_ic(AbstractionModel1,ic="loo")
AbstractionModel1 <- add_ic(AbstractionModel1,ic="kfold")

AbstractionModel2 <- brm(Strategy ~ 1 + Condition + (1|ID), data=Strategy, family=cumulative("logit"))
AbstractionModel2 <- add_ic(AbstractionModel2,ic="loo")
AbstractionModel2 <- add_ic(AbstractionModel2,ic="kfold")

ICs <- loo_compare(AbstractionModel2,AbstractionModel1,AbstractionModel0)
Ws <- model_weights(AbstractionModel2,AbstractionModel1,AbstractionModel0)

ICs
Ws

# Found that Abstraction model 2 was the most optimal.
# Creating priors, testing them and using this model for hypothesis 1 and 2

```


# Part 2
Testing hypothesis 1 and 2

```{r}

## Defining the formula
AbstractionModel2_f <- Strategy ~ 1 + Condition + (1|ID)

# Which priors do I need?
get_prior(AbstractionModel2_f, 
                         data=Strategy, 
                         family = cumulative("logit"))

summary(Strategy)

# Defining the priors
AbstractionModel2_p <- c(
  prior(normal(0, 1.5), class = Intercept), #creating a sceptical prior that include all the data
  prior(normal(0, 2), class = b), # changed the prior from 0, 1 to 0, 2 to ensure all possible outcomes was included.
  prior(normal(0, .2), class = sd)
)


#### Fitting the model only using the prior (no data)
AbstractionModel2_m_prior <- brm(AbstractionModel2_f, 
                         data = Strategy, 
                         family = cumulative("logit"),
                         prior = AbstractionModel2_p,
                         sample_prior = "only",
                         cores = 2, 
                         chains= 2,
                         #backend = "cmdstanr",
                         ##threads = threading(2),
                         control = list(
                           adapt_delta=0.99,
                           max_treedepth=20
                         ))


# Checking if the model has reasonable predictions from the priors
pp_check(AbstractionModel2_m_prior, nsamples=100)

# Fitting the model on the data
AbstractionModel2_m <- brm(AbstractionModel2_f, 
                         data = Strategy, 
                         family = cumulative("logit"),
                         prior = AbstractionModel2_p,
                         sample_prior = TRUE,
                         cores = 2, 
                         chains= 2,
                         #backend = "cmdstanr",
                         ##threads = threading(2),
                         control = list(
                           adapt_delta=0.99,
                           max_treedepth=20
                         ))


# the priors is resonable 
pp_check(AbstractionModel2_m, nsamples = 100)

post <- posterior_samples(AbstractionModel2_m)

#Checking the model

## Prior for the intercepts
ggplot(post) + theme_classic() +
  geom_density(aes(prior_Intercept), alpha=0.2, fill="salmon") + 
  geom_density(aes(`b_Intercept[1]`), alpha=0.4, fill="green") + 
  geom_density(aes(`b_Intercept[2]`), alpha=0.4, fill="blue")

## Prior for the betas
ggplot(post) + theme_classic() +
  geom_density(aes(prior_b), alpha=0.2, fill="salmon") + 
  geom_density(aes(b_ConditionC_FlexPair), alpha=0.4, fill="green") +
  geom_density(aes(b_ConditionB_ConstantPair), alpha=0.4, fill="blue")

## Prior for the sd
ggplot(post) + theme_classic() +
  geom_density(aes(prior_sd_ID), alpha=0.2, fill="salmon") + 
  geom_density(aes(sd_ID__Intercept), alpha=0.4, fill="green")

## Add the loo
AbstractionModel2 <- add_ic(AbstractionModel2_m, criterion = "loo")
AbstractionModel2 <- add_ic(AbstractionModel2, criterion = "kfold")
summary(AbstractionModel2)

## Test hypothesis 1:
## Are Individuals less able to generalize than pairs (at both thresholds)?
hypothesis(AbstractionModel2, "Intercept[1] < (Intercept[1]+ ConditionB_ConstantPair + Intercept[1] + ConditionC_FlexPair)/2")
plot(hypothesis(AbstractionModel2, "Intercept[1]< (Intercept[1]+ConditionB_ConstantPair + Intercept[1] + ConditionC_FlexPair)/2"))
hypothesis(AbstractionModel2, "Intercept[2] < (Intercept[2] + ConditionB_ConstantPair + Intercept[2] + ConditionC_FlexPair)/2")
plot(hypothesis(AbstractionModel2, "Intercept[2] < (Intercept[2]+ ConditionB_ConstantPair+ Intercept[2] + ConditionC_FlexPair)/2"))

## Test the hypotheses (in probability space):
post <- post %>% mutate(
  Individual1 = inv_logit_scaled(`b_Intercept[1]`),
  Individual2 = inv_logit_scaled(`b_Intercept[2]`),
  Pairs1 = inv_logit_scaled(`b_Intercept[1]` + b_ConditionB_ConstantPair),
  Pairs2 = inv_logit_scaled(`b_Intercept[2]` + b_ConditionB_ConstantPair), 
  FlexPairs1 = inv_logit_scaled(`b_Intercept[1]` + b_ConditionC_FlexPair),
  FlexPairs2 = inv_logit_scaled(`b_Intercept[2]` + b_ConditionC_FlexPair)
)

## Plot over marginal effects
marginal_effects(AbstractionModel2, 'Condition', categorical = TRUE)

#Estimates
mean((post$Pairs1 + post$FlexPairs1)/2 - post$Individual1)
quantile((post$Pairs1 + post$FlexPairs1)/2 - post$Individual1, c(0.025, 0.975))
#ER
sum(((post$Pairs1 + post$FlexPairs1)/2 - post$Individual1)>0)/sum(((post$Pairs1 + post$FlexPairs1)/2 - post$Individual1)<=0)

## Results for this hypothesis
#b = -1.86, CIs = -3.07, -0.70, EviRatio = 665.67

post$b_Individual1=post$`b_Intercept[1]`
post$b_Individual2=post$`b_Intercept[2]`
post$b_Pair1=post$`b_Intercept[1]` + post$b_ConditionB_ConstantPair
post$b_Pair2=post$`b_Intercept[2]` + post$b_ConditionB_ConstantPair
post$b_FlexPair1=post$`b_Intercept[1]`+post$b_ConditionC_FlexPair
post$b_FlexPair2=post$`b_Intercept[2]`+post$b_ConditionC_FlexPair

# Plot 1
ggplot(post) +
  geom_density(aes(b_Individual1),fill="red",alpha=0.3) +
  geom_density(aes(b_Pair1),fill="blue",alpha=0.3) + 
  geom_density(aes(b_FlexPair1),fill="yellow",alpha=0.3) +
  theme_classic()



## Test the hypothesis H2
# Flex pairs are better then constant pairs
hypothesis(AbstractionModel2, "Intercept[1] + ConditionB_ConstantPair < Intercept[1] + ConditionC_FlexPair")
plot(hypothesis(AbstractionModel2, "Intercept[1] + ConditionB_ConstantPair< Intercept[1] + ConditionC_FlexPair"))
hypothesis(AbstractionModel2, "Intercept[2] + ConditionB_ConstantPair< Intercept[2] + ConditionC_FlexPair")
plot(hypothesis(AbstractionModel2, "Intercept[2]+ ConditionB_ConstantPair <  Intercept[2] + ConditionC_FlexPair"))

#Not supported
## Results for this hypothesis
# b = 0.38, CIs = - 0.99, 1.76, EviRatio = 0.47 

## Tested the oppisit of hypothesis 2
hypothesis(AbstractionModel2, "Intercept[1] + ConditionB_ConstantPair > Intercept[1] + ConditionC_FlexPair")
plot(hypothesis(AbstractionModel2, "Intercept[1] + ConditionB_ConstantPair> Intercept[1] + ConditionC_FlexPair"))
hypothesis(AbstractionModel2, "Intercept[2] + ConditionB_ConstantPair> Intercept[2] + ConditionC_FlexPair")
plot(hypothesis(AbstractionModel2, "Intercept[2]+ ConditionB_ConstantPair >  Intercept[2] + ConditionC_FlexPair"))


#Concluding there is no more evidence for flex pairs then for constant pairs


#Making a plot to describe the diversity of the levels
marginal_effects(AbstractionModel2,ordinal=TRUE)
marginal_effects(AbstractionModel2,categorical=TRUE)

```

# Part 3 
Testing Hypothesis 3
- if the amount of communication within the pair may effect the level of abstraction they reach 

```{r}

# Loading data concerining communication - the value of verbal communication.
Communication <- read.csv("Communication_duration.csv")

# Comparing the different models

Communication$VC_duration_in_sec <- as.numeric(Communication$VC_duration_in_sec)
Communication$teamwork <- as.numeric(Communication$teamwork)

M0 <- brm(Strategy ~ 1 + (1|ID), data=Communication, family=cumulative("logit"))
M0 <- add_ic(M0,ic="loo")
M0 <- add_ic(M0,ic="kfold")

M1 <- brm(Strategy ~ 1 + Condition + (1|ID),data = Communication, family=cumulative('logit'))
M1 <- add_ic(M1,ic="loo")
M1 <- add_ic(M1,ic="kfold")

QM1 <- brm(Strategy ~ 1 + scale(VC_duration_in_sec) + (1|ID), data=Communication, family=cumulative("logit"))
QM1 <- add_ic(QM1,ic="loo")
QM1 <- add_ic(QM1,ic="kfold")

QM2 <- brm(Strategy ~ 1 + scale(teamwork) + (1|ID), data=Communication, family=cumulative("logit"))
QM2 <- add_ic(QM2,ic="loo")
QM2 <- add_ic(QM2,ic="kfold")

QM3 <- brm(Strategy ~ 1 + scale(teamwork) + scale(VC_duration_in_sec) + (1|ID), data=Communication, family=cumulative("logit"))
QM3 <- add_ic(QM3,ic="loo")
QM3 <- add_ic(QM3,ic="kfold")

QM4 <- brm(Strategy ~ 1 + scale(teamwork) * scale(VC_duration_in_sec) + (1|ID), data=Communication, family=cumulative("logit"))
QM4 <- add_ic(QM4,ic="loo")
QM4 <- add_ic(QM4,ic="kfold")

QM5 <- brm(Strategy ~ 1 + Condition + scale(teamwork) + scale(VC_duration_in_sec) + (1|ID), data=Communication, family=cumulative("logit"))
QM5 <- add_ic(QM5,ic="loo")
QM5 <- add_ic(QM5,ic="kfold")

QM6 <- brm(Strategy ~ 1 + scale(teamwork) * scale(VC_duration_in_sec) + Condition + (1|ID), data=Communication, family=cumulative("logit"))
QM6 <- add_ic(QM6,ic="loo")
QM6 <- add_ic(QM6,ic="kfold")



Loo <- loo_compare(M0, M1, QM1, QM2,QM3,QM4,QM5,QM6)
Ws <- model_weights(M0, M1, QM1, QM2,QM3,QM4,QM5,QM6)

Loo
Ws

#Supports the theory that the quality of the communication effected the outcome 

```



# Part 4 
Testing hypothesis 4

```{r}
## Looking at the fourth hypothesis

# iv)	Participants with a higher level of abstraction in the first part of the part of the study will be faster and more accurate in solving the more complex version of the gear problem (transfer) 


## only looking at part 2 data
Strategy <- read_csv("StrategyCoding.csv")
Strategy$Strategy <- ordered(Strategy$Strategy)


Logs <- read_csv("Logfiles.csv")
Logs <- Logs[ -c(1) ]

#Logs$condition <- str_replace(Logs$condition, pattern = "A", "")
#Logs$condition <- str_replace(Logs$condition, pattern = "B", "")

part2 <- subset(Logs, 
                 part == 'Part3' & correct == 1)


part2$correct <- as.numeric(part2$correct)


part2_b <- part2 %>% 
  group_by(ID) %>%
  count(correct)

part2_b$Accuracy <- part2_b$n
part2 <- part2_b[ c(1,4)]

data <- merge(part2, Strategy)
data <- data [-c(5)]

data$Strat <- data$Strategy
data$Strategy <- str_replace(data$Strategy, pattern = "1", "one")
data$Strategy <- str_replace(data$Strategy, pattern = "2", "two")
data$Strategy <- str_replace(data$Strategy, pattern = "3", "three")

data$Strategy <- ordered(data$Strategy, levels = c('one','two','three'))
data$Condition <- ordered(data$Condition, levels = c('Individual','Constant Pair','Flex Pair'))
data$Accuracy <- ordered(data$Accuracy)


#creating the different models and testing for the best
TransferModel0 <- brm(Accuracy ~ 1 + (1|ID), data=data, family=cumulative("logit"))
TransferModel0 <- add_criterion(TransferModel0,criterion ="loo")
TransferModel0 <- add_criterion(TransferModel0,criterion="kfold")

TransferModel1 <- brm(Accuracy ~ 1 + Strategy, data=data, family=cumulative("logit"))
TransferModel1 <- add_criterion(TransferModel1,criterion="loo")
TransferModel1 <- add_criterion(TransferModel1,criterion="kfold")

TransferModel2 <- brm(Accuracy ~ 1 + Strategy + (1|ID), data=data, family=cumulative("logit"))
TransferModel2 <- add_criterion(TransferModel2,criterion="loo")
TransferModel2 <- add_criterion(TransferModel2,criterion="kfold")

Loo_trans <- loo_compare(TransferModel0, TransferModel1, TransferModel2)
Ws_trans <- model_weights(TransferModel0, TransferModel1, TransferModel2)

Loo_trans
Ws_trans

# using transfer model 2



## Defining the formula
TransferModel_f <- Accuracy ~ 1 + Strategy + (1|ID)

# Which priors do I need?
get_prior(TransferModel_f, 
                         data=data, 
                         family = cumulative("logit"))

summary(data)

# Defining the priors
TransferModel_p <- c(
  prior(normal(0, 1.5), class = Intercept), 
  prior(normal(0, 1), class = b), 
  prior(normal(0, .2), class = sd)
)


#Fitting the model only using the prior (no data)
TransferModel_m_prior <- brm(TransferModel_f, 
                         data = data, 
                         family = cumulative("logit"),
                         prior = TransferModel_p,
                         sample_prior = "only",
                         cores = 2, 
                         chains= 2,
                         #backend = "cmdstanr",
                         ##threads = threading(2),
                         control = list(
                           adapt_delta=0.99,
                           max_treedepth=20
                         ))


# Checking if the model has reasonable predictions from the priors
pp_check(TransferModel_m_prior, nsamples=100)

# Fitting the model on the data
TransferModel_m <- brm(TransferModel_f, 
                         data = data, 
                         family = cumulative("logit"),
                         prior = TransferModel_p,
                         sample_prior = TRUE,
                         cores = 2, 
                         chains= 2,
                         #backend = "cmdstanr",
                         ##threads = threading(2),
                         control = list(
                           adapt_delta=0.99,
                           max_treedepth=20
                         ))


# The priors is resonable 
pp_check(TransferModel_m, nsamples = 100)


post <- posterior_samples(TransferModel_m)


# Prior for the intercepts
ggplot(post) + theme_classic() +
  geom_density(aes(prior_Intercept), alpha=0.2, fill="salmon") + 
  geom_density(aes(`b_Intercept[1]`), alpha=0.4, fill="green") + 
  geom_density(aes(`b_Intercept[2]`), alpha=0.4, fill="blue") +
  geom_density(aes(`b_Intercept[3]`), alpha=0.4, fill="yellow")

# Prior for the betas
ggplot(post) + theme_classic() +
  geom_density(aes(prior_b), alpha=0.2, fill="salmon") + 
  geom_density(aes(b_Strategy.L), alpha=0.4, fill="green") +
  geom_density(aes(b_Strategy.Q), alpha=0.4, fill="blue")

# Prior for the sd
ggplot(post) + theme_classic() +
  geom_density(aes(prior_sd_ID), alpha=0.2, fill="salmon") + 
  geom_density(aes(sd_ID__Intercept), alpha=0.4, fill="green")

# Add the loo
TransferModel <- add_criterion(TransferModel_m, criterion = "loo")
TransferModel <- add_criterion(TransferModel,criterion ="kfold")
summary(TransferModel)

marginal_effects(TransferModel, 'Strategy', categorical = TRUE)
marginal_effects(TransferModel, 'Strategy', ordinal = TRUE)



# Ploting the data
plots <- data %>% 
  group_by(Strategy, Accuracy) %>% 
  count(Accuracy)

plots$Accuracy <- as.character(plots$Accuracy)



ggplot(plots, aes(Strategy, Accuracy)) + 
  theme_classic() +
  geom_bar(aes(fill = n))
  

ggplot(data = data, aes(Strategy, Accuracy)) + 
  theme_classic() +
  geom_point() 
  
ggplot(data = plots, aes(Accuracy)) + 
  geom_bar()
  


plot <- ggplot(data, aes(Strategy))

plot + geom_bar(position = "stack", aes(fill = Accuracy))


ggplot(data=plots, aes(x=Strategy, y=n, fill=Accuracy)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=n), vjust=1.6, color="black",
            position = position_dodge(0.9), size=3.5)+
  scale_fill_brewer(palette="Greens")+
  theme_minimal() +
  labs(title = "Accuracy within the different levels of abstraction", x = 'Level of abstraction in part 1', y = 'Number of participants')


p + labs(title="Plot of length  per dose", 
         x="Dose (mg)", y = "Length")+
   scale_fill_manual(values=c('black','lightgray'))+
   theme_classic()



## Testing the hypothesis 
#Participants with a higher level of abstraction in the first part of the part of the study will be faster and more accurate in solving the more complex version of the gear problem (transfer) 

summary(TransferModel)

#Testing if strategy 2 does better then strategy 1
hypothesis(TransferModel, "Intercept[1] < Strategytwo + Intercept[1]")
plot(hypothesis(TransferModel, "Intercept[1] < Strategytwo + Intercept[1]"))

hypothesis(TransferModel, "Intercept[2] < Strategytwo + Intercept[2]")
plot(hypothesis(TransferModel, "Intercept[2] < Strategytwo + Intercept[2]"))

hypothesis(TransferModel, "Intercept[3] < Strategytwo + Intercept[3]")
plot(hypothesis(TransferModel, "Intercept[3] < Strategytwo + Intercept[3]"))

# Results for this hypothesis
# b = -0.97, CIs = - 1.91, -0.07, EviRatio = 24.64 



#Testing if strategy 3 does better then strategy 1
hypothesis(TransferModel, "Intercept[1] < Strategythree + Intercept[1]")
plot(hypothesis(TransferModel, "Intercept[1] < Strategythree + Intercept[1]"))

hypothesis(TransferModel, "Intercept[2] < Strategythree + Intercept[2]")
plot(hypothesis(TransferModel, "Intercept[2] < Strategythree + Intercept[2]"))

hypothesis(TransferModel, "Intercept[3] < Strategythree + Intercept[3]")
plot(hypothesis(TransferModel, "Intercept[3] < Strategythree + Intercept[3]"))

# Results for this hypothesis
# b = 0.26, CIs = -0.64, 1.18, EviRatio = 0.44



#Testing if strategy 1 does better then strategy 3
hypothesis(TransferModel, "Intercept[1] > Strategythree + Intercept[1]")
plot(hypothesis(TransferModel, "Intercept[1] > Strategythree + Intercept[1]"))

hypothesis(TransferModel, "Intercept[2] > Strategythree + Intercept[2]")
plot(hypothesis(TransferModel, "Intercept[2] > Strategythree + Intercept[2]"))

hypothesis(TransferModel, "Intercept[3] > Strategythree + Intercept[3]")
plot(hypothesis(TransferModel, "Intercept[3] > Strategythree + Intercept[3]"))

# Results for this hypothesis
# b = 0.26, CIs = -0.64, 1.18, EviRatio = 2.25




#Testing if strategy 3 does better then strategy 2
hypothesis(TransferModel, "Intercept[1] + Strategytwo < Strategythree + Intercept[1]")
plot(hypothesis(TransferModel, "Intercept[1] < Strategythree + Intercept[1]"))

hypothesis(TransferModel, "Intercept[2] + Strategytwo < Strategythree + Intercept[2]")
plot(hypothesis(TransferModel, "Intercept[2] + Strategytwo < Strategythree + Intercept[2]"))

hypothesis(TransferModel, "Intercept[3] + Strategytwo < Strategythree + Intercept[3]")
plot(hypothesis(TransferModel, "Intercept[3] + Strategytwo < Strategythree + Intercept[3]"))

# Results for this hypothesis
# b = 1.23, CIs = 0.34, 2.17, EviRatio = 0.01 




#Testing if strategy 2 does better then strategy 3
hypothesis(TransferModel, "Intercept[1] + Strategytwo > Strategythree + Intercept[1]")
plot(hypothesis(TransferModel, "Intercept[1] > Strategythree + Intercept[1]"))

hypothesis(TransferModel, "Intercept[2] + Strategytwo > Strategythree + Intercept[2]")
plot(hypothesis(TransferModel, "Intercept[2] + Strategytwo > Strategythree + Intercept[2]"))

hypothesis(TransferModel, "Intercept[3] + Strategytwo > Strategythree + Intercept[3]")
plot(hypothesis(TransferModel, "Intercept[3] + Strategytwo > Strategythree + Intercept[3]"))


# Results for this hypothesis
# b = 1.23, CIs = 0.34, 2.17, EviRatio = 89.91 

```

